

## 人工智能：
让机器具有人类的智能（多流派）

研究领域：
* 机器感知（计算机视觉、语音信息处理、模式识别）
* 学习（机器学习、强化学习）
* 语言（自然语言处理）
* 记忆（知识表达）
* 决策（规划、数据挖掘）

开发人工智能系统：
* 专家系统（人工规划）
	用于处理简单问题，如：区分直角和非直角
--> 部分场景人工无法定义合适的规则，如：语音识别、文字识别

* 无法人工规划
-->机器学习 - 构造一个映射函数
构造过程：
* 准备数据（训练样本）
* 提取特征
* 获取特征对应的输出变量
* 设计一个*学习算法*来学习特征与输出变量之间的相关性模型
* 测试，使用测试数据，验证模型是否预测准确

![[deepLearing_1.png]]

机器学习步骤：
![[deepLearning_2.png]]

浅层学习：不涉及特征学习，其特征主要靠人工经验或特征转换方法来抽取（传统的特征提取）

## 表示学习：
语义鸿沟（人工智能挑战之一）：底层特征和高层语义之间的相关性。

表示方法：
* 局部表示
* 分布式表示（表示能力更强，能够计算相关性） 例：RGB颜色

![[deepLearning_3.png]]

特征提取vs表示学习：
* 特征学习：基于任务或先验 去去除无用特征 
* 表示学习：通过深度学习模型学习高层语义特征（依赖分类器结果，端到端学习）

## 深度学习

![[deepLearning_4.png]]

包括了多级特征提取和预测（分类器）

难点：**贡献度分配问题**
无法很好界定各级对结果的影响

## 神经网络：

以人脑神经元为灵感

![[deepLearning_5.png]]

人工神经元：
![[deepLearning_6.png]]

人工神经网络 主要由大量的人工神经元以及它们之间的有向连接构成，主要考虑：
* 神经元的激活规则
* 网络的拓扑结构
* 学习算法

神经网络类型：
![[deepLearning_7.png]]

输入层->隐藏层->隐藏层->...->输出层

如何解决贡献度问题：
可导性 ----> 偏导数衡量贡献度


## 机器学习：

从有限的观测数据中学习（或“猜测”）出具有一般性的规律，并利用这些规律对未知数据进行预测的方法。
（单纯总结规律，是拟合问题，而机器学习需要再规律的基础上做预测）

![[deepLearning_8.png]]

处理问题：
* 回归问题   ---- 监督学习应用 （y为连续值）
* 分类问题   ---- 监督学习应用 （y∈{0, 1}）
* 聚类问题（只有x，没有y，通过学习添加标签）  ---- 无监督学习应用 
* 降维   ---- 无监督学习应用 
* 密度估计    ---- 无监督学习应用 
* 学习、决策（与环境交互来进行学习）---- 强化学习应用

常见机器学习类型：
![[deepLearning_9.png]]

学习准则：
一个好的模型应该在所有取值上都与真实映射函数一致
	--> 损失函数：非负实数函数，用于量化模型预测和真实标签之间的差异
	--> 寻找期望风险（损失函数期望）的最小化
	--> 通过大数定律，通过计算训练数据的均值，来近似期望风险（经验风险）
	--> 转化为最优化问题，寻找最小经验风险

**梯度下降法**
参考：https://zhuanlan.zhihu.com/p/580645925
梯度函数是损失函数对于模型参数的偏导数，梯度向量指向损失函数增加最快的方向
* 迭代方法
* 学习率（超参数，人为设定），与梯度共同决定变化步长

批量梯度下降：使用全部样本
随机梯度下降法：取单个训练样本，相较于批量更快，但不一定得到最优解
小批量（mini-batch）随机梯度下降法：取小部分训练样本

**机器学习 ≠ 优化问题**

![[deepLearning_10.png]]

欠拟合问题：优化不足
过拟合问题：过度优化，采样数据正确率为0，但是在未知数据（测试数据）正确率很低
过拟合问题通常由 模型复杂度过高 或者 采样数据过少导致

机器学习希望模型在采样数据和测试数据上都有较好的正确率，即同时注重期望风险和经验风险。
而优化则是不断降低经验风险的过程

泛化误差：期望风险和泛化风险间的差异

减少泛化误差方法：正则化 --> 所有损害优化的方法都是正则化（降低复杂度）
* 增加优化约束：L1/L2约束、数据增强
* 干扰优化过程：权重衰减、随机梯度下降、提前停止
	提前停止：验证集上错误率不再下降时停止


## 回归问题


线性回归：